{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "browser = webdriver.Chrome()\n",
    "browser.maximize_window()\n",
    "\n",
    "browser.get(\"https://pureportal.coventry.ac.uk/en/organisations/coventry-university/persons/\")    # Coventry URL Site\n",
    "time.sleep(5)\n",
    "browser.find_element_by_xpath(\"/html/body/div[3]/div[3]/div/div[1]/div/div[2]/div/button[2]\").click() # Accept Cookies\n",
    "\n",
    "for i in range(0 , 45):\n",
    "    \n",
    "        # Profiles per Page\n",
    "        Cov_Page_Url = \"https://pureportal.coventry.ac.uk/en/organisations/coventry-university/persons/?page=%d\"%(i)\n",
    "        browser.get(Cov_Page_Url)\n",
    "        a = browser.page_source\n",
    "        resp=BeautifulSoup(a,\"html.parser\")\n",
    "        \n",
    "        Cov_Page_Profiles = resp.find(class_ = 'grid-results')\n",
    "        Cov_Page_Profiles_2 = Cov_Page_Profiles.find_all('h3') # User details\n",
    "        \n",
    "        # Load Each Profile in page\n",
    "        for prof in Cov_Page_Profiles_2:\n",
    "            \n",
    "            Profile_Url = prof.find('a')\n",
    "            Profile_Url_2 = Profile_Url['href'] + '/publications'            \n",
    "            browser.get(Profile_Url_2)\n",
    "            b = browser.page_source\n",
    "            resp1 = BeautifulSoup(b,\"html.parser\")\n",
    "            \n",
    "#             Research_Output = browser.find_element_by_xpath(\"/html/body/main/div[1]/section/div[2]/div/div/nav/ul/li[4]/a/span/i\")\n",
    "\n",
    "            \n",
    "            if(resp1.find(class_='icon icon-publications') != None):\n",
    "                Cov_Research_Paper = resp1.find(class_='list-results')\n",
    "                Cov_Research_Paper_2 = Cov_Research_Paper.find_all('h3')   #Research Papers Count in the first page\n",
    "                \n",
    "                # Create Empty array to store URL's of User Research Paper\n",
    "                urls=[]\n",
    "                \n",
    "                for paper in Cov_Research_Paper_2:\n",
    "                    Cov_Research_Paper_3 = paper.find('a')\n",
    "                    Cov_Research_Paper_4 = Cov_Research_Paper_3['href'] # each research paper\n",
    "                    urls.append(Cov_Research_Paper_4)\n",
    "                    \n",
    "                try:\n",
    "                    while(browser.find_element_by_xpath(\"/html/body/main/div[1]/div/div/section/nav/ul/li[3]/a\") != None):\n",
    "                        Res_Pap_Page = resp1.find(class_='next')\n",
    "    #                     Resp_Pap_Page_2 = Res_Pap_Page.find(class_='next')\n",
    "                        Res_Pap_Page_3 = Res_Pap_Page.find('a')\n",
    "                        Research_Url = 'https://pureportal.coventry.ac.uk' + Res_Pap_Page_3['href']\n",
    "                        browser.get(Research_Url)\n",
    "                        e = browser.page_source\n",
    "                        resp5 = BeautifulSoup(e,\"html.parser\")\n",
    "                        Cov_Research_Paper = resp1.find(class_='list-results')\n",
    "                        Cov_Research_Paper_2 = Cov_Research_Paper.find_all('h3')   #Research Papers Count in the consecutive page\n",
    "                        for paper in Cov_Research_Paper_2:\n",
    "                            Cov_Research_Paper_3 = paper.find('a')\n",
    "                            Cov_Research_Paper_4 = Cov_Research_Paper_3['href'] # each research paper\n",
    "                            urls.append(Cov_Research_Paper_4)\n",
    "                except:\n",
    "                    time.sleep(0)\n",
    "                \n",
    "#                 print(urls)\n",
    "                    \n",
    "                \n",
    "                for Cov_Pap in urls:\n",
    "\n",
    "                    browser.get(Cov_Pap)\n",
    "                    c = browser.page_source\n",
    "                    resp3=BeautifulSoup(c,\"html.parser\")\n",
    "            \n",
    "                    Res_Title = resp3.find(class_='rendering')\n",
    "                    Cov_Title = Res_Title.get_text()\n",
    "                        \n",
    "                    Res_Dept = resp3.find(class_='relations organisations')    # Capture Department Details                        \n",
    "                    if(Res_Dept != None):\n",
    "                        Cov_Dept_2 = Res_Dept.find('a')\n",
    "                        if(Cov_Dept_2 != None):\n",
    "                            Cov_Department = Cov_Dept_2.get_text()\n",
    "                        else:\n",
    "                            Cov_Department = \"\"\n",
    "                    else:\n",
    "                        Cov_Department = \"\"\n",
    "                            \n",
    "                    Res_Year = resp3.find(class_='status')     # Publication Year\n",
    "                    if(Res_Year != None):\n",
    "                        Cov_Publ = Res_Year.find(class_='date')\n",
    "                        Cov_Publ_2 = Cov_Publ.get_text()\n",
    "                        Cov_Year = Cov_Publ_2[-4:]\n",
    "                    else:\n",
    "                        Cov_Year = \"\"\n",
    "                            \n",
    "                    Res_Doc = resp3.find(class_='content-sidebar publication-sidebar')    # Access to Doc Link\n",
    "                    Cov_Doc_2 = resp3.find(class_='doi')\n",
    "                    if(Res_Doc != None and Cov_Doc_2 != None):\n",
    "                        Cov_Doc_3 = Cov_Doc_2.find('a')\n",
    "                        Cov_Document = Cov_Doc_3['href']\n",
    "                    else:\n",
    "                        Cov_Document = \"\"\n",
    "                            \n",
    "                    Res_Abstract = resp3.find(class_='textblock')             # Research_Paper_Abstract\n",
    "                    if(Res_Abstract != None):\n",
    "                        Cov_Abstract = Res_Abstract.get_text()\n",
    "                    else:\n",
    "                        Cov_Abstract = \"\"\n",
    "\n",
    "                    authors = resp3.find(class_='relations persons')\n",
    "                    if(authors != None):\n",
    "                        Cov_Authors = authors.get_text()\n",
    "                    else:\n",
    "                        Cov_Authors = \"\"\n",
    "\n",
    "# #                     Fingerprint = browser.find_element_by_xpath(\"/html/body/main/div[1]/section/div[2]/div/div/nav/ul/li[2]/a/span/i\")\n",
    "                        \n",
    "                    \n",
    "                    if(resp3.find(class_= 'icon icon-fingerprint') != None):\n",
    "                        interests = []\n",
    "                        FP_Url = Cov_Pap + '/fingerprints'\n",
    "                        browser.get(FP_Url)\n",
    "                        d = browser.page_source\n",
    "                        resp4 = BeautifulSoup(d,\"html.parser\")\n",
    "                        Res_FP = resp4.find_all(class_='publication-fingerprint-thesauri')\n",
    "                        if (Res_FP != None):\n",
    "                            for fp in Res_FP:\n",
    "                                Cov_Interests = fp.find('h3').get_text()\n",
    "                                interests.append(Cov_Interests)\n",
    "                            Cov_Interests = ','.join(interests)\n",
    "                        else:\n",
    "                            Cov_Interests = \"\"\n",
    "                    else:\n",
    "                        Cov_Interests = \"\"\n",
    "                        \n",
    "                    Scrapped_Cov_Data = {\n",
    "                            'Title': Cov_Title,\n",
    "                            'Publications Authors': Cov_Authors,\n",
    "                            'Department': Cov_Department,\n",
    "                            'Publication Year': Cov_Year,\n",
    "                            'Paper Link': Cov_Pap,\n",
    "                            'Tags':Cov_Interests,\n",
    "                            'Access to Doc.': Cov_Document,\n",
    "                            'Abstract':Cov_Abstract\n",
    "                          }\n",
    "\n",
    "                    with open(\"Final_Cov_Research_Paper.json\", \"a+\") as outfile:\n",
    "                        json.dump(Scrapped_Cov_Data, outfile)\n",
    "                        outfile.write(\"\\n\")\n",
    "            else:\n",
    "                time.sleep(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
